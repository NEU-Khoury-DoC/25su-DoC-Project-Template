{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training of Final DNN\n",
    "This jupyter notebook file is where the final version of the DNN is trained and saved. It is written to be fully reproducible.\n",
    "\n",
    "\n",
    "I created a new env to run this file and its sister file (dnn_load_test.ipynb). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/temp-doc-tfff/lib/python3.10/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 74.0080 - mae: 7.6443 - val_loss: 64.7343 - val_mae: 6.9077\n",
      "Epoch 2/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 48.8049 - mae: 6.0384 - val_loss: 52.2980 - val_mae: 6.0103\n",
      "Epoch 3/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 26.3855 - mae: 4.1161 - val_loss: 35.9779 - val_mae: 4.6443\n",
      "Epoch 4/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 11.4617 - mae: 2.5496 - val_loss: 24.7144 - val_mae: 3.5714\n",
      "Epoch 5/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.2160 - mae: 1.9631 - val_loss: 19.3958 - val_mae: 3.0796\n",
      "Epoch 6/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.6313 - mae: 1.5730 - val_loss: 15.9225 - val_mae: 2.7838\n",
      "Epoch 7/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.7370 - mae: 1.4345 - val_loss: 13.1362 - val_mae: 2.4848\n",
      "Epoch 8/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.7936 - mae: 1.2556 - val_loss: 10.0426 - val_mae: 2.1598\n",
      "Epoch 9/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.2987 - mae: 1.1744 - val_loss: 8.4755 - val_mae: 1.9409\n",
      "Epoch 10/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.0064 - mae: 1.0968 - val_loss: 6.1112 - val_mae: 1.7576\n",
      "Epoch 11/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7741 - mae: 0.9921 - val_loss: 6.5325 - val_mae: 1.7486\n",
      "Epoch 12/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5432 - mae: 0.9242 - val_loss: 5.6344 - val_mae: 1.7077\n",
      "Epoch 13/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4856 - mae: 0.9128 - val_loss: 4.9172 - val_mae: 1.5735\n",
      "Epoch 14/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4591 - mae: 0.8797 - val_loss: 4.7443 - val_mae: 1.5474\n",
      "Epoch 15/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2462 - mae: 0.8008 - val_loss: 4.6585 - val_mae: 1.5047\n",
      "Epoch 16/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0579 - mae: 0.7775 - val_loss: 4.5317 - val_mae: 1.4091\n",
      "Epoch 17/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2192 - mae: 0.8047 - val_loss: 4.5570 - val_mae: 1.4889\n",
      "Epoch 18/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1097 - mae: 0.7919 - val_loss: 4.3311 - val_mae: 1.4883\n",
      "Epoch 19/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0356 - mae: 0.7687 - val_loss: 4.4805 - val_mae: 1.4902\n",
      "Epoch 20/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8467 - mae: 0.6819 - val_loss: 3.8126 - val_mae: 1.4224\n",
      "Epoch 21/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8309 - mae: 0.6550 - val_loss: 4.0099 - val_mae: 1.3946\n",
      "Epoch 22/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7823 - mae: 0.6765 - val_loss: 3.9817 - val_mae: 1.3923\n",
      "Epoch 23/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7145 - mae: 0.6422 - val_loss: 3.9661 - val_mae: 1.4282\n",
      "Epoch 24/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8812 - mae: 0.7067 - val_loss: 3.6486 - val_mae: 1.3650\n",
      "Epoch 25/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7362 - mae: 0.6428 - val_loss: 4.1317 - val_mae: 1.4723\n",
      "Epoch 26/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8196 - mae: 0.6582 - val_loss: 4.3368 - val_mae: 1.4720\n",
      "Epoch 27/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6300 - mae: 0.6029 - val_loss: 4.3038 - val_mae: 1.4410\n",
      "Epoch 28/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6172 - mae: 0.5561 - val_loss: 3.7779 - val_mae: 1.3392\n",
      "Epoch 29/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5197 - mae: 0.5406 - val_loss: 4.2699 - val_mae: 1.3772\n",
      "Epoch 30/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5695 - mae: 0.5693 - val_loss: 3.8718 - val_mae: 1.3218\n",
      "Epoch 31/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4997 - mae: 0.5342 - val_loss: 4.2125 - val_mae: 1.4003\n",
      "Epoch 32/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4924 - mae: 0.5066 - val_loss: 3.9953 - val_mae: 1.3748\n",
      "Epoch 33/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5317 - mae: 0.5528 - val_loss: 3.4773 - val_mae: 1.3239\n",
      "Epoch 34/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7375 - mae: 0.6040 - val_loss: 3.6243 - val_mae: 1.3071\n",
      "Epoch 35/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4426 - mae: 0.4971 - val_loss: 3.4567 - val_mae: 1.2921\n",
      "Epoch 36/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4247 - mae: 0.4894 - val_loss: 3.9506 - val_mae: 1.3168\n",
      "Epoch 37/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4581 - mae: 0.4895 - val_loss: 3.9278 - val_mae: 1.3293\n",
      "Epoch 38/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4078 - mae: 0.4801 - val_loss: 4.2044 - val_mae: 1.3877\n",
      "Epoch 39/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5082 - mae: 0.5457 - val_loss: 4.2632 - val_mae: 1.3642\n",
      "Epoch 40/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4683 - mae: 0.5163 - val_loss: 3.7706 - val_mae: 1.2859\n",
      "Epoch 41/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4240 - mae: 0.5030 - val_loss: 3.7330 - val_mae: 1.2814\n",
      "Epoch 42/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5246 - mae: 0.5387 - val_loss: 2.9721 - val_mae: 1.2221\n",
      "Epoch 43/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3192 - mae: 0.4156 - val_loss: 4.0998 - val_mae: 1.3181\n",
      "Epoch 44/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3298 - mae: 0.4267 - val_loss: 4.0502 - val_mae: 1.3029\n",
      "Epoch 45/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3658 - mae: 0.4711 - val_loss: 3.6671 - val_mae: 1.2776\n",
      "Epoch 46/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4189 - mae: 0.4773 - val_loss: 3.4013 - val_mae: 1.2800\n",
      "Epoch 47/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3147 - mae: 0.4156 - val_loss: 3.8808 - val_mae: 1.3221\n",
      "Epoch 48/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3542 - mae: 0.4305 - val_loss: 4.1719 - val_mae: 1.3340\n",
      "Epoch 49/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4142 - mae: 0.4569 - val_loss: 4.0094 - val_mae: 1.3037\n",
      "Epoch 50/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3592 - mae: 0.4250 - val_loss: 3.7124 - val_mae: 1.3649\n",
      "Epoch 51/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3958 - mae: 0.4770 - val_loss: 4.0962 - val_mae: 1.4131\n",
      "Epoch 52/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3916 - mae: 0.4790 - val_loss: 3.6508 - val_mae: 1.3150\n",
      "Epoch 53/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3270 - mae: 0.4304 - val_loss: 3.9426 - val_mae: 1.3723\n",
      "Epoch 54/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3198 - mae: 0.4353 - val_loss: 4.0736 - val_mae: 1.3784\n",
      "Epoch 55/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2729 - mae: 0.3925 - val_loss: 4.3322 - val_mae: 1.4086\n",
      "Epoch 56/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3964 - mae: 0.4263 - val_loss: 3.5831 - val_mae: 1.3431\n",
      "Epoch 57/300\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3419 - mae: 0.4378 - val_loss: 3.9315 - val_mae: 1.3481\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "MAE: 1.42\n",
      "MSE: 3.96\n",
      "RMSE: 1.99\n",
      "R² Score: 0.75\n",
      "\n",
      "Predicted Unemployment: 6.97%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "RANDOM_SEED = 11 # for reproduciblity\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('../datasets/MEGAFRAME_CLEANEDV2.csv')\n",
    "\n",
    "# Prepare features and target\n",
    "X = df.drop(columns=['UNEMP', 'Reference area', 'REF_AREA', 'TIME_PERIOD'])\n",
    "y = df['UNEMP']\n",
    "\n",
    "# Define feature types\n",
    "categorical_features = ['Region']\n",
    "numerical_features = X.columns.difference(categorical_features)\n",
    "\n",
    "# Create and fit preprocessor\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numerical_features),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "])\n",
    "\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Save preprocessing parameters manually\n",
    "import json\n",
    "\n",
    "preprocessing_params = {\n",
    "    'numerical_features': list(numerical_features),\n",
    "    'categorical_features': categorical_features,\n",
    "    'scaler_mean': preprocessor.named_transformers_['num'].mean_.tolist(),\n",
    "    'scaler_scale': preprocessor.named_transformers_['num'].scale_.tolist(),\n",
    "    'encoder_categories': [cat.tolist() for cat in preprocessor.named_transformers_['cat'].categories_]\n",
    "}\n",
    "\n",
    "with open('preprocessing_params.json', 'w') as f:\n",
    "    json.dump(preprocessing_params, f, indent=2)\n",
    "\n",
    "# Define model architecture\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', kernel_regularizer=l2(0.0001), input_shape=(X_processed.shape[1],)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.02),\n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.0001)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.02),\n",
    "    Dense(32, activation='relu', kernel_regularizer=l2(0.0001)),\n",
    "    BatchNormalization(),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Create reproducible train/validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_processed, y, test_size=0.1, random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "# Set up early stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train, \n",
    "          epochs=300, \n",
    "          batch_size=8, \n",
    "          validation_data=(X_val, y_val), \n",
    "          callbacks=[early_stop],\n",
    "          verbose=1)\n",
    "\n",
    "# Evaluate model performance\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "y_pred = model.predict(X_processed)\n",
    "\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "mae = mean_absolute_error(y, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y, y_pred)\n",
    "\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"MSE: {mse:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R² Score: {r2:.2f}\")\n",
    "\n",
    "# Save trained model\n",
    "model.save('Unemployment_AI_Revisions.keras')\n",
    "\n",
    "# Test prediction on example data\n",
    "new_data = pd.DataFrame({\n",
    "    'Region': ['Europe and Central Asia'],  \n",
    "    'Trade union density': [78.699997],\n",
    "    'Combined corporate income tax rate': [28.0],\n",
    "    'Education spending': [0.0734319847255705],\n",
    "    'Health spending': [0.0631525528524754],\n",
    "    'Housing spending': [0.0057497428086187],\n",
    "    'Community development spending': [0.0025634702523358],\n",
    "    'IRLT': [5.1075],\n",
    "    'Population, total': [8895960.0],\n",
    "    'GDP per capita (current US$)': [27259.4806735435],\n",
    "    'Inflation, consumer prices (annual %)': [2.40595834145438],\n",
    "    'Gini index': [26.5]\n",
    "})\n",
    "\n",
    "new_data_processed = preprocessor.transform(new_data)\n",
    "predicted_unemployment = model.predict(new_data_processed, verbose=0)\n",
    "print(f\"\\nPredicted Unemployment: {predicted_unemployment.flatten()[0]:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temp-doc-tfff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
